# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ltk1Fg4Los-rY2m6eAjx3q2k_SlsDN9J
"""

pip install streamlit

import streamlit as st
import pandas as pd
import re
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

# ========== Load & Preprocess Data ==========
@st.cache_data
def load_data():
    df = pd.read_csv("drugsComTrain_raw.csv")
    df = df.dropna(subset=['condition'])

    # Text cleaning
    def clean_text(text):
        text = re.sub(r'<.*?>', '', str(text))
        text = re.sub(r'[^a-zA-Z\s]', '', text)
        return text.lower()

    stopwords = {
        'i', 'me', 'my', 'we', 'you', 'your', 'he', 'she', 'it', 'they', 'them',
        'what', 'which', 'this', 'that', 'am', 'is', 'are', 'was', 'were', 'be',
        'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'a', 'an', 'the',
        'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by',
        'for', 'with', 'about', 'against', 'between', 'to', 'from', 'in', 'out', 'on',
        'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there',
        'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',
        'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same',
        'so', 'than', 'too', 'very', 'can', 'will', 'just', 'now'
    }

    def preprocess(text):
        tokens = text.split()
        return ' '.join([word for word in tokens if word not in stopwords])

    df['processed_review'] = df['review'].apply(clean_text).apply(preprocess)
    df['sentiment'] = df['rating'].apply(lambda x: 1 if x >= 7 else 0)
    return df

df = load_data()

# ========== Train Model ==========
X = df['processed_review']
y = df['sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
tfidf = TfidfVectorizer(max_features=5000)
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

model = LogisticRegression(max_iter=1000)
model.fit(X_train_tfidf, y_train)

# ========== Web App UI ==========
st.set_page_config(page_title="Drug Review Analyzer", layout="centered")
st.title("💊 Drug Review Analyzer")
st.write("Analyze review sentiment and get top drugs for a medical condition.")

tab1, tab2, tab3 = st.tabs(["🧪 Predict Sentiment", "💡 Recommend Drugs", "📊 Model Info"])

# Tab 1: Predict Sentiment
with tab1:
    st.subheader("Enter a Review:")
    user_review = st.text_area("Write a drug review here:")
    if st.button("Analyze Sentiment"):
        cleaned = re.sub(r'[^a-zA-Z\s]', '', user_review.lower())
        tokens = ' '.join([word for word in cleaned.split() if word not in tfidf.stop_words_])
        vectorized = tfidf.transform([tokens])
        pred = model.predict(vectorized)[0]
        st.success("✅ Positive Review" if pred == 1 else "❌ Negative Review")

# Tab 2: Recommend Drugs
with tab2:
    st.subheader("Enter a Medical Condition:")
    condition_input = st.text_input("e.g., Depression, Pain, Birth Control")
    if st.button("Get Top Drugs"):
        subset = df[df['condition'].str.contains(condition_input, case=False, na=False)]
        top = (
            subset[subset['sentiment'] == 1]
            .groupby('drugName')
            .size()
            .sort_values(ascending=False)
            .head(5)
        )
        if not top.empty:
            st.write(f"Top drugs for **{condition_input.title()}**:")
            st.table(top.reset_index().rename(columns={0: "Positive Reviews"}))
        else:
            st.warning("No data found for that condition.")

# Tab 3: Model Info
with tab3:
    st.subheader("Model Info")
    st.markdown("""
    - **Model**: Logistic Regression
    - **Vectorization**: TF-IDF (max_features=5000)
    - **Sentiment Definition**: Rating >= 7 → Positive (1), else Negative (0)
    - **Accuracy** (on test set): {:.2f}%
    """.format(model.score(X_test_tfidf, y_test) * 100))